# -*- coding: utf-8 -*-
"""OOP UTS MD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13ilG-4-iAMHTgCrCNQxL9qtJM6GQBp9O
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, f1_score, confusion_matrix, roc_curve, roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
import seaborn as sns

class LoanModelPipeline:
    def __init__(self, model_type='xgboost'):
        self.model_type = model_type.lower()
        self.model = None
        self.scaler = StandardScaler()
        self.standard_scaler_col = ['person_age', 'person_income', 'loan_amnt', 'loan_int_rate', 'credit_score']

    def clean_gender(self, g):
        if pd.isna(g): return np.nan
        g = g.lower().replace(" ", "")
        if g == 'male': return 'male'
        elif g == 'female': return 'female'
        return np.nan

    def preprocess(self, df):
        df['person_income'].fillna(df['person_income'].median(), inplace=True)
        df['person_gender'] = df['person_gender'].apply(self.clean_gender)

        df['person_gender'] = df['person_gender'].map({'male': 1, 'female': 0})
        df['previous_loan_defaults_on_file'] = df['previous_loan_defaults_on_file'].map({'Yes': 1, 'No': 0})

        df = pd.get_dummies(df, columns=[
            'person_education', 'person_home_ownership', 'loan_intent'
        ], prefix=[
            'edu', 'home', 'intent'
        ], drop_first=True)

        return df

    def load_and_prepare_data(self, path):
        df = pd.read_csv(path)
        df = self.preprocess(df)
        X = df.drop(columns=['loan_status'])
        y = df['loan_status']

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        X_train[self.standard_scaler_col] = self.scaler.fit_transform(X_train[self.standard_scaler_col])
        X_test[self.standard_scaler_col] = self.scaler.transform(X_test[self.standard_scaler_col])

        return X_train, X_test, y_train, y_test

    def train(self, X_train, y_train):
        if self.model_type == 'xgboost':
            self.model = XGBClassifier(random_state=42, max_depth=3, n_estimators=100, learning_rate=0.1)
        else:
            self.model = RandomForestClassifier(random_state=42, max_depth=10, n_estimators=100)

        self.model.fit(X_train, y_train)

    def evaluate(self, X_test, y_test):
        y_pred = self.model.predict(X_test)
        y_pred_proba = self.model.predict_proba(X_test)[:, 1]

        print(f"\nClassification Report ({self.model_type.upper()}):")
        print(classification_report(y_test, y_pred))
        print(f"F1 Score ({self.model_type.upper()}):", f1_score(y_test, y_pred))
        print(confusion_matrix(y_test, y_pred))

        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        auc = roc_auc_score(y_test, y_pred_proba)

        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc:.2f})', color='darkorange', lw=2)
        plt.plot([0, 1], [0, 1], linestyle='--', color='navy', lw=2)
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'ROC Curve ({self.model_type.upper()})')
        plt.legend(loc='lower right')
        plt.show()